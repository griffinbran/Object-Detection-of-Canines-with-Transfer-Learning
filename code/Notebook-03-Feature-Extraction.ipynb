{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%store <var_name>\n",
    "#%store -r <var_name>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import  models\n",
    "# load VGG-16 model: 23 layers, 138,357,544 params, 528MB\n",
    "from keras.applications.vgg16 import VGG16\n",
    "# load and evaluate a saved model \n",
    "#import tensorflow as tf\n",
    "#from tensorflow import keras\n",
    "from keras.models import load_model\n",
    "\n",
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Imports from Sci-Kit Learn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import metrics\n",
    "\n",
    "# Load data from previous notebooks\n",
    "%store -r dog_data_part2\n",
    "%store -r X_valid\n",
    "%store -r y_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43733"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_valid)\n",
    "len(y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0, 1}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(224, 224, 3)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_valid[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Length X_valid:  2142917\n"
     ]
    }
   ],
   "source": [
    "# Load target labels for validation data set\n",
    "try:\n",
    "    with open('../../assets/y_validation_labels.txt', 'r') as validlabels:\n",
    "        # Store validation images as variable for loading into model for scoring\n",
    "        y_valid_loaded = np.array([valid_image_label for valid_image_label in validlabels])\n",
    "\n",
    "    # Load feature matrix of Validation images from text file\n",
    "    with open('../../assets/X_validation_image_data.txt', 'r') as validimages:\n",
    "        # Store validation images as variable for loading into model for scoring\n",
    "        X_valid_loaded = np.array([processed_image for processed_image in validimages])\n",
    "\n",
    "    # Check that all is copacetic\n",
    "    type(dog_data_part2), dog_data_part2[0], type(dog_data_part2[0])\n",
    "    # Length of list of images\n",
    "    print('Final Length X_valid: ', len(X_valid_loaded)) \n",
    "    \n",
    "# Just in case the data can be loaded from text, we want to know!\n",
    "except FileNotFoundError:\n",
    "    print('HEADS UP: Could not load validation images/labels from .txt files...\\n\\\n",
    "                \\t...return to previous notebooks, store pre-processed data, and re-run this cell.')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.str_"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_valid_loaded[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n",
      "Model: \"functional_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# https://keras.io/api/applications/vgg/#vgg16-function\n",
    "# https://towardsdatascience.com/a-demonstration-of-transfer-learning-of-vgg-convolutional-neural-network-pre-trained-model-with-c9f5b8b1ab0a\n",
    "\n",
    "# Adjust input size of the model for include_top=False\n",
    "# new_input = Input(shape=(224,224,3)) --> MUST INCLUDE THIS PARAM AFTER CLASSIFICATION\n",
    "\n",
    "# load the model weights into memory\n",
    "base_model = VGG16(\n",
    "                include_top=True,   # include_top=False to load model wihtout the fully-connected output layers used to make predictions\n",
    "                weights=\"imagenet\", # Weights are downloaded automatically when instantiating a model: Keras Applications ~/.keras/models/\n",
    "                input_tensor=None,  # input_tensor = new_input = Input(shape=(224,224,3))\n",
    "                input_shape=None,\n",
    "                pooling=None,\n",
    "                classes=1000,\n",
    "                classifier_activation=\"softmax\",\n",
    "            )\n",
    "\n",
    "# Cut-Off the VGG-16 Model after the last Conv2D layer (18)\n",
    "dogg16 = models.Model(inputs=base_model.input,\n",
    "                           outputs=base_model.get_layer('flatten').output\n",
    "                          )\n",
    "\n",
    "# Extract features\n",
    "#flatten_features = model_vgg16.predict(x)\n",
    "# save model and architecture to single file\n",
    "dogg16.save('../../model_dogg16.h5') \n",
    "print(\"Saved model to disk\")\n",
    "\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "model.compile('adam', #optimizer=\n",
    "              loss=\"categorical_crossentropy\", # 'binary_crossentropy'\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "# Summarize the loaded model after dropping the two fully connected layers and the output layer\n",
    "dogg16.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Notes from General Assembly-DSI Lessons \n",
    "4.01-lesson-logistic-regression/\n",
    "<br>4.02-lesson-regularization/\n",
    "<br>4.03-lesson-knn/\n",
    "<br>4.04-lesson-classification_metrics_i/\n",
    "<br>4.05-lesson-classification-metrics-ii/\n",
    "<br>4.06-lesson-hyperparameters-gridsearch-and-pipelines/\n",
    "<br>4.07-lesson-hypothesis-testing/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(x=train_imgs_scaled, \n",
    "                    y=train_labels_enc,\n",
    "                    validation_data=(validation_imgs_scaled, validation_labels_enc),\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EDA might be handy to use:\n",
    "# 1. .where()\n",
    "# 2. .value_counts(normalize = True)\n",
    "# 3. .astype(int)\n",
    "#EXAMPLE: Turn outcome to 1 if success and 0 if failure\n",
    "df['outcome'] = np.where(df['target'] == 'Success Condition', 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 0: Assemble X and y\n",
    "features = ['feat1', 'feat2'] # predictor variables {x}\n",
    "X = df[features]; # predictor variables\n",
    "y = df[ 'target' ]; # our target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load weights into new model\n",
    "loaded_model = '../../model_vgg16_flatten.h5'\n",
    "\n",
    "# Load base model weights\n",
    "loaded_model = load_model(loaded_model)\n",
    "#loaded_model.load_weights(\"~\\.keras\\models.h5\") \n",
    "print(\"Loaded model from disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:dsi]",
   "language": "python",
   "name": "conda-env-dsi-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
