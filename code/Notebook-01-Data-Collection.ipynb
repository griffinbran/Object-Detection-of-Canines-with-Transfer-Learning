{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notebook 01: Data Collection and Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installs without warnings in conda env: dsi\n",
    "#!pip install visual_genome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle\n",
    "import json\n",
    "from zipfile import ZipFile\n",
    "# Import OpenCV(cv2 module)\n",
    "import cv2\n",
    "# Import Python's standard utility module 'os' for interacting with Operating System\n",
    "import os\n",
    "# Import the Python wrapper for the VG API\n",
    "from visual_genome import api"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run cell only once to retrieve all image ID's from Visual Genome API and then store as a txt file for future reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve an array of integers representing all VG image ID's from API\n",
    "image_ids = api.get_all_image_ids()\n",
    "\n",
    "# Save array as txt file to bypass API next time\n",
    "with open('../data/image_ids.txt', 'w') as imagehandles:\n",
    "    imagehandles.writelines(\"%s\\n\" % ids for ids in image_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(108077, list, '1', str)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load Image ID's from text file\n",
    "with open('../data/image_ids.txt', 'r') as imagehandles:\n",
    "    # Store Image ID's as variable for image pre-processing, removing the endline character in the process\n",
    "    image_ids = [image_id[:-1] for image_id in imagehandles]\n",
    "# Check that all is copacetic\n",
    "len(image_ids), type(image_ids), image_ids[0], type(image_ids[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The processing method provided by the Visual Genome API, using relation mappings, is too slow to be effective in obtaining the object descriptions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of Images in dataset: 108,077 stored in \"json_objects\", a <class 'list'> of <class 'dict'>s\n"
     ]
    }
   ],
   "source": [
    "# Read objects.json file from Visual Genome, to retrieve the object data for each image\n",
    "with open('../../objects.json', 'r') as objects_json_file:\n",
    "    # Store a list of len(json_objects) = 108_077 dictionaries representing image object data\n",
    "    json_objects = json.load(objects_json_file)\n",
    "print(f'No. of Images in dataset: {len(json_objects):,} stored in \"json_objects\", a {type(json_objects)} of {type(json_objects[0])}s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Identify all dog pics in data and count them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of dog images in VG dataset: 3235\n"
     ]
    }
   ],
   "source": [
    "# loop thru each item in list\n",
    "dog_pic_ids = []\n",
    "for image_index in range(len(json_objects)):\n",
    "    # Number of objects\n",
    "    # len(json_objects[image_index]) = 3\n",
    "    # json_objects[image_index].keys() = dict_keys(['image_id', 'objects', 'image_url'])\n",
    "    num_objects = len(json_objects[image_index]['objects'])\n",
    "    # loop through objects_index searching for dog objects\n",
    "    objects_index = 0\n",
    "    # Objects_index lives in range(num_objects)\n",
    "    while objects_index < num_objects:\n",
    "        # Save image_id's of images with dogs\n",
    "        if json_objects[image_index]['objects'][objects_index][ 'names' ] == [  'dog'  ]:\n",
    "      # if json_objects[image_index]['objects'][objects_index]['synsets'] == ['dog.n.01']:\n",
    "    #####NOTICE: INSERT HOT DOG FILTER HERE LOL!\n",
    "            # Save image_id's of images with dogs\n",
    "            image_id = json_objects[image_index]['image_id']\n",
    "            dog_pic_ids.append(image_id)\n",
    "            # Escape 'while-loop' as soon as 'dog'-object found\n",
    "            objects_index = num_objects\n",
    "        else:\n",
    "            # Move on to next object in image, continue searching\n",
    "            objects_index += 1\n",
    "# Check how many dog pics were discovered in the dataset\n",
    "print(f'Total number of dog images in VG dataset: {len(dog_pic_ids)}')\n",
    "# Save dog_pic_ids as txt file to bypass loading object data from json next time\n",
    "with open('../data/dog_pic_ids.txt', 'w') as imagehandles:\n",
    "    imagehandles.writelines(\"%s\\n\" % ids for ids in dog_pic_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Identify and store dog pic image ID's specific to VG Part 2 Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Dog Pics in VG Part 2 Dataset: 1240\n"
     ]
    }
   ],
   "source": [
    "# NOTICE CODE FROM\n",
    "# https://thispointer.com/python-how-to-get-the-list-of-all-files-in-a-zip-archive/\n",
    "\n",
    "# Prepare to store dog pic image ID's in VG Part 2 Dataset\n",
    "dog_data_part2 = []\n",
    "\n",
    "# ~5.5 GB ZIP Archive, 40% of total data set\n",
    "with ZipFile('../../visual_genome_part2.zip', \"r\") as z:\n",
    "    # One file in zip archive\n",
    "    VG_100K_2 = z.namelist()\n",
    "\n",
    "    # Iterate over image file names, 'VG_100K_2/image_id.jpg'\n",
    "    for ith_image in VG_100K_2: \n",
    "        # Get extension of file, '.jpg'\n",
    "        ext = os.path.splitext(ith_image)[-1]\n",
    "        # Get root of file, root = VG_100K_2/image_id.jpg\n",
    "        root = os.path.splitext(ith_image)[0]\n",
    "        \n",
    "        # Skip over Archive Directory\n",
    "        if (ext == \".jpg\"):\n",
    "            # Skip root[:10]='VG_100K_2' in dog_pic_ids\n",
    "            if int(root[10:]) in dog_pic_ids:\n",
    "                dog_data_part2.append(int(root[10:]))\n",
    "                \n",
    "# Display percent of total dog images that live in VG Part 2 dataset\n",
    "print(f'Number of Dog Pics in VG Part 2 Dataset: {len(dog_data_part2)}')\n",
    "\n",
    "# Save dog_data_part2 as txt file to load in model tuning notebook\n",
    "with open('../data/dog_data_part2.txt', 'w') as imagehandles:\n",
    "    imagehandles.writelines(\"%s\\n\" % ids for ids in dog_data_part2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Identify and store dog pic image ID's specific to VG Part 1 Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Dog Pics in VG Part 1 Dataset: 1995\n"
     ]
    }
   ],
   "source": [
    "dog_data_part1 = []\n",
    "for image_id in dog_pic_ids:\n",
    "    if image_id not in dog_data_part2:\n",
    "        dog_data_part1.append(image_id)\n",
    "print(f'Number of Dog Pics in VG Part 1 Dataset: {len(dog_data_part1)}')\n",
    "\n",
    "# Save dog_data_part2 as txt file to load in model tuning notebook\n",
    "with open('../data/dog_data_part1.txt', 'w') as imagehandles:\n",
    "    imagehandles.writelines(\"%s\\n\" % ids for ids in dog_data_part1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dog pics in each VG dataset identified\n",
      "\n",
      "Percent of Dog Pics in VG Part 1 Dataset: 61.67%\n",
      "Percent of Dog Pics in VG Part 2 Dataset: 38.33%\n"
     ]
    }
   ],
   "source": [
    "# Check that all  is copacetic\n",
    "if len(dog_data_part1) + len(dog_data_part2) == len(dog_pic_ids):\n",
    "    print('Dog pics in each VG dataset identified')\n",
    "else:\n",
    "    print('Something is wrong')\n",
    "print()\n",
    "\n",
    " # Display percent of total dog images that live in VG Part 1 dataset\n",
    "print(f'Percent of Dog Pics in VG Part 1 Dataset: {100*len(dog_data_part1)/len(dog_pic_ids):.2f}%')\n",
    "# Display percent of total dog images that live in VG Part 2 dataset\n",
    "print(f'Percent of Dog Pics in VG Part 2 Dataset: {100*len(dog_data_part2)/len(dog_pic_ids):.2f}%')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dog_pics_objs_dict2 = []\n",
    "for objects in range(len(json_objects)):\n",
    "    for dog in dog_data_part2:\n",
    "        if json_objects[objects]['image_id'] == dog:\n",
    "            dog_pics_objs_dict2.append(json_objects[objects])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1419\n",
      "1419\n"
     ]
    }
   ],
   "source": [
    "# Object IDs of all dog objects (each image with a dog has a unique ID and each dog object has a unique ID)\n",
    "dogject_ids = []\n",
    "for image_idx in range(len(dog_pics_objs_dict2)):\n",
    "    for object_idx in range(len(dog_pics_objs_dict2[image_idx]['objects'])):\n",
    "        if dog_pics_objs_dict2[image_idx]['objects'][object_idx]['synsets'] == ['dog.n.01']:\n",
    "            dogject_ids.append(dog_pics_objs_dict2[image_idx]['objects'][object_idx]['object_id'])\n",
    "print(len(dogject_ids))\n",
    "print(len(set(dogject_ids)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display ****ALL**** Dog Images in Visual Genome Part 2 Dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTICE CODE FROM\n",
    "# https://thispointer.com/python-how-to-get-the-list-of-all-files-in-a-zip-archive/\n",
    "\n",
    "# ~5.5 GB ZIP Archive, 40% of total data set\n",
    "with ZipFile('../../visual_genome_part2.zip', \"r\") as z:\n",
    "    # One file in zip archive\n",
    "    VG_100K_2 = z.namelist()\n",
    "\n",
    "    # Iterate over image file names, 'VG_100K_2/image_id.jpg'\n",
    "    for ith_image in VG_100K_2: \n",
    "        # Get extension of file, '.jpg'\n",
    "        ext = os.path.splitext(ith_image)[-1]\n",
    "        # Get root of file, root = VG_100K_2/image_id.jpg\n",
    "        root = os.path.splitext(ith_image)[0]\n",
    "        \n",
    "        # Skip over Archive Directory\n",
    "        if (ext == \".jpg\"):\n",
    "            # Skip root[:10]='VG_100K_2' in dog_pic_ids\n",
    "            if int(root[10:]) in dog_pic_ids:\n",
    "                # Read image binary data of 'VG_100K_2' from zip archive('visual_genome_part2.zip')\n",
    "                in_bytes = z.read(ith_image) # VG_100K_2/\n",
    "                # Decode bytes to image\n",
    "                img = cv2.imdecode(np.frombuffer(in_bytes, np.uint8), cv2.IMREAD_COLOR)\n",
    "    \n",
    "                # Output img with window name as 'image' \n",
    "################# WARNING WARNING WARNING: Running this cell with the following line uncommented will require force kernel restart\n",
    "################# Unless you wait for all images (1240 images * 1 sec hold > 20 minutes!)\n",
    "                #cv2.imshow('img', img)\n",
    "                # Display for 1sec = 1_000ms\n",
    "                #cv2.waitKey(1000)\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hot Dog filter clearly needed after browsing all pphotos, maybe 6-10 images are actually just hot dogs\n",
    "#for dog in dog_pic_ids:\n",
    "    # Consider what "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output from first 03 iterations thru training dataset for paths1:\n",
      "\n",
      "d = 10.jpg\n",
      "Training LABELS:  {10}\n",
      "Training paths:  [('../../visual_genome_part1/VG_100K_1/10.jpg', '10', 0)]\n",
      "\n",
      "d = 107899.jpg\n",
      "Training LABELS:  {10, 107899}\n",
      "Training paths:  [('../../visual_genome_part1/VG_100K_1/10.jpg', '10', 0), ('../../visual_genome_part1/VG_100K_1/107899.jpg', '107899', 0)]\n",
      "\n",
      "d = 107900.jpg\n",
      "Training LABELS:  {10, 107899, 107900}\n",
      "Training paths:  [('../../visual_genome_part1/VG_100K_1/10.jpg', '10', 0), ('../../visual_genome_part1/VG_100K_1/107899.jpg', '107899', 0), ('../../visual_genome_part1/VG_100K_1/107900.jpg', '107900', 0)]\n",
      "\n",
      "Output from first 03 iterations thru validation dataset for paths2:\n",
      "\n",
      "d = 1.jpg\n",
      "Validation LABELS:  {1}\n",
      "Validation paths:  [('../../visual_genome_part2/VG_100K_2/1.jpg', '1', 0)]\n",
      "\n",
      "d = 100.jpg\n",
      "Validation LABELS:  {1, 100}\n",
      "Validation paths:  [('../../visual_genome_part2/VG_100K_2/1.jpg', '1', 0), ('../../visual_genome_part2/VG_100K_2/100.jpg', '100', 0)]\n",
      "\n",
      "d = 1000.jpg\n",
      "Validation LABELS:  {1000, 1, 100}\n",
      "Validation paths:  [('../../visual_genome_part2/VG_100K_2/1.jpg', '1', 0), ('../../visual_genome_part2/VG_100K_2/100.jpg', '100', 0), ('../../visual_genome_part2/VG_100K_2/1000.jpg', '1000', 0)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Path to Training data\n",
    "BASEPATH1 = '../../visual_genome_part1/VG_100K_1/'\n",
    "# Path to Validation data\n",
    "BASEPATH2 = '../../visual_genome_part2/VG_100K_2/'\n",
    "\n",
    "# Images in Train set: Part 1 \n",
    "LABELS1 = set() # {set of integers of image_ids }\n",
    "paths1 = [] # [List of tuples ('string of full image path + file name', 'image_id')...(64_344 out of 108_077 tuples/images) ]\n",
    "\n",
    "# Images in Validation set: Part 2 {set of integers of image_ids }\n",
    "LABELS2 = set() # {set of integers of image_ids }\n",
    "paths2 = [] # [List of tuples ('string of full image path + file name', 'image_id')...(43_733 out of 108_077 tuples/images) ]\n",
    "\n",
    "# For the Training Data\n",
    "print('Output from first 03 iterations thru training dataset for paths1:\\n')\n",
    "check = 0\n",
    "\n",
    "# For each file in training dataset...\n",
    "for d in os.listdir(BASEPATH1):\n",
    "    img_idx = int(d[:-4])\n",
    "    LABELS1.add(img_idx)\n",
    "    # Check each image to see if it is or is not in the list of dog images\n",
    "    if img_idx not in dog_data_part1:\n",
    "        # Label zero for NO DOG\n",
    "        paths1.append((BASEPATH1+d, d[:-4], 0)) # replace d[:-4] with \n",
    "    elif img_idx in dog_data_part1:\n",
    "        # Label one for DOG\n",
    "        paths1.append((BASEPATH1+d, d[:-4], 1))   \n",
    "    if check < 3:\n",
    "        print('d =', d)\n",
    "        print('Training LABELS: ', LABELS1)\n",
    "        print('Training paths: ', paths1)\n",
    "        print()\n",
    "        check += 1\n",
    "        \n",
    "# For the Validation Data\n",
    "print('Output from first 03 iterations thru validation dataset for paths2:\\n')\n",
    "check = 0\n",
    "# For each file in validation dataset...\n",
    "for d in os.listdir(BASEPATH2):\n",
    "    img_idx = int(d[:-4])\n",
    "    LABELS2.add(img_idx)\n",
    "    # Check each image to see if it is or is not in the list of dog images\n",
    "    if img_idx not in dog_data_part2:\n",
    "        # Label zero for NO DOG\n",
    "        paths2.append((BASEPATH2+d, d[:-4], 0))\n",
    "    elif img_idx in dog_data_part2:\n",
    "        # Label one for DOG\n",
    "        paths2.append((BASEPATH2+d, d[:-4], 1))   \n",
    "    if check < 3:\n",
    "        print('d =', d)\n",
    "        print('Validation LABELS: ', LABELS2)\n",
    "        print('Validation paths: ', paths2)\n",
    "        print()\n",
    "        check += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1995\n",
      "1240\n"
     ]
    }
   ],
   "source": [
    "# Check that all is copacetic with dog ID's\n",
    "\n",
    "# Training set\n",
    "dog = 0\n",
    "for i in range(len(paths1)):\n",
    "    if paths1[i][2] == 1:\n",
    "        dog += 1\n",
    "print(dog)\n",
    "\n",
    "# Validation set\n",
    "dog = 0\n",
    "for i in range(len(paths2)):\n",
    "    if paths2[i][2] == 1:\n",
    "        dog += 1\n",
    "print(dog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output from first three iterations in training:\n",
      "\n",
      "path:  ../../visual_genome_part1/VG_100K_1/10.jpg\n",
      "image_id:  10\n",
      "tag_label:  0\n",
      "\n",
      "Properly Labeled Dog Pics (out of 1995): 1995\n",
      "Properly Labeled Dogless Pics (out of 62,179):  62,351\n"
     ]
    }
   ],
   "source": [
    "# Check that all is copacetic with the Training set labeling above\n",
    "count_dog_p1 = 0\n",
    "count_dogless_p1 = 0\n",
    "print('Output from first three iterations in training:\\n')\n",
    "check = 0\n",
    "for path, image_id, tag_label in paths1: # dtypes = ('str', 'str', int)\n",
    "    if tag_label == 1:\n",
    "        count_dog_p1 += 1\n",
    "    elif tag_label == 0:\n",
    "        count_dogless_p1 += 1\n",
    "    if check < 1:\n",
    "        print('path: ', path)\n",
    "        print('image_id: ', image_id)\n",
    "        print('tag_label: ', tag_label)\n",
    "        print()\n",
    "        check += 1\n",
    "print(f'Properly Labeled Dog Pics (out of 1995): {count_dog_p1}\\nProperly Labeled Dogless Pics (out of 62,179):  {count_dogless_p1:,}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function to prepare data for input to VGG-16 Network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resizing and converting to RGB\n",
    "def load_and_preprocess_image(path):\n",
    "    image = cv2.imread(path)\n",
    "    image = cv2.resize(image, (224,224))\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The code in the cell below will first check for an existing X_valid array of processed data stored in {.txt, .csv, .pkl} files\n",
    "> * If the try results in a FinalNotFoundError, X-images and y-labels arrays will be created"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setup X_train and y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting to load binary X_train from pkl...\n",
      "Attempting to load binary y_train from pkl...\n",
      "Training data loaded!\n",
      "\n",
      "Final No. of Dog labels in training set:  1995\n",
      "Final Length X_train:  64346\n",
      "Wall time: 1min 58s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Load target labels for training data set\n",
    "try:\n",
    "    print('Attempting to load binary X_train from pkl...')\n",
    "    # Save X_train and y_train arrays as pkl files in assets folder (just outside of Github repo) to load in Notebook 3\n",
    "    with open('../../assets/X_training_image_data.pkl', 'rb') as file:\n",
    "        X_train = pickle.load(file)\n",
    "\n",
    "    print('Attempting to load binary y_train from pkl...')\n",
    "    with open('../../assets/y_training_labels.pkl', 'rb') as file:\n",
    "        y_train = pickle.load(file)\n",
    "    print('Training data loaded!')\n",
    "    print()\n",
    "    # Check that all is copacetic\n",
    "    len(X_train), type(dog_data_part1), dog_data_part1[0], type(dog_data_part1[0])\n",
    "    # No. of target labels/tags equal to one\n",
    "    count_dogs = 0\n",
    "    for ones in y_train:\n",
    "        if ones == 1:\n",
    "            count_dogs += 1\n",
    "    print('Final No. of Dog labels in training set: ', count_dogs) \n",
    "    # Length of list of images\n",
    "    print('Final Length X_train: ', len(X_train)) \n",
    "    \n",
    "# Just in case the data cannot be loaded from pickled protocol, we want to know!\n",
    "except FileNotFoundError:\n",
    "    print('HEADS UP: Could not load taining images/labels from .pkl files...\\n\\\n",
    "                \\t...hold on for ~10-15 mins while X and y are prepared')\n",
    "    print()\n",
    "    # Build a feature matrix \n",
    "    X_train = []\n",
    "    y_train = []\n",
    "    check = 0\n",
    "    count_dogs = 0\n",
    "    # Recall that paths1 and paths2 have 3-tuple info for each image in dataset\n",
    "    for  path, image_id, tag_label in paths1:  # dtypes = ('str', 'str', int)\n",
    "        #for image_path in os.listdir(path):\n",
    "        image = load_and_preprocess_image(path)\n",
    "         # X[image_index] image corresponds to image_id = paths1[image_index][1]\n",
    "        X_train.append(image)\n",
    "        # y[image_index] label corresponds to image_id = paths1[image_index][1]\n",
    "        y_train.append(tag_label) \n",
    "        # Just a simple counter of the number of ones to cofirm with known number of dog images\n",
    "        if tag_label == 1:\n",
    "            count_dogs += 1\n",
    "        check += 1\n",
    "        # Only display load status a few times throughout the entire pre-process\n",
    "        if check % 10000 == 0:\n",
    "            print('path: ', path)\n",
    "            print('image_id: ', image_id)\n",
    "            print('No. of Dog labels so far: ', count_dogs) # No. of target labels/tags equal to one\n",
    "            print('Length X_train: ', len(X_train)) # Length of list of images\n",
    "            print()\n",
    "    # Display final outcome of pre-processing\n",
    "    print('Total No. of Dog labels: ', count_dogs) # No. of target labels/tags equal to one\n",
    "    print('Final Length X_train: ', len(X_train)) # Length of list of images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64346, {0, 1})"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(paths1), set(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setup X-valid and y-valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting to load binary X_valid from pkl...\n",
      "Attempting to load binary y_valid from pkl...\n",
      "Validation data loaded!\n",
      "\n",
      "Final No. of Dog labels in validation set:  1240\n",
      "Final Length X_valid:  43733\n",
      "Wall time: 1min 1s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Load target labels for validation data set\n",
    "try:\n",
    "    print('Attempting to load binary X_valid from pkl...')\n",
    "    # Save X_valid and y_valid arrays as pkl files in assets folder (just outside of Github repo) to load in Notebook 3\n",
    "    with open('../../assets/X_validation_image_data.pkl', 'rb') as file:\n",
    "        X_valid = pickle.load(file)\n",
    "\n",
    "    print('Attempting to load binary y_valid from pkl...')\n",
    "    with open('../../assets/y_validation_labels.pkl', 'rb') as file:\n",
    "        y_valid = pickle.load(file)\n",
    "    print('Validation data loaded!')\n",
    "    print()\n",
    "    # Check that all is copacetic\n",
    "    len(X_valid), type(dog_data_part1), dog_data_part1[0], type(dog_data_part1[0])\n",
    "    # No. of target labels/tags equal to one\n",
    "    count_dogs = 0\n",
    "    for ones in y_valid:\n",
    "        if ones == 1:\n",
    "            count_dogs += 1\n",
    "    print('Final No. of Dog labels in validation set: ', count_dogs) \n",
    "    # Length of list of images\n",
    "    print('Final Length X_valid: ', len(X_valid)) \n",
    "    \n",
    "# Just in case the data can be loaded from text, we want to know!\n",
    "except FileNotFoundError:\n",
    "    print('HEADS UP: Could not load taining images/labels from .pkl files...\\n\\\n",
    "                \\t...hold on for ~10-15 mins while X and y are prepared')\n",
    "    print()\n",
    "    # Build a feature matrix \n",
    "    X_valid = []\n",
    "    y_valid = []\n",
    "    check = 0\n",
    "    count_dogs = 0\n",
    "    # Recall that paths1 and paths2 have 3-tuple info for each image in dataset\n",
    "    for  path, image_id, tag_label in paths2:  # dtypes = ('str', 'str', int)\n",
    "        #for image_path in os.listdir(path):\n",
    "        image = load_and_preprocess_image(path)\n",
    "         # X[image_index] image corresponds to image_id = paths2[image_index][1]\n",
    "        X_valid.append(image)\n",
    "        # y[image_index] label corresponds to image_id = paths2[image_index][1]\n",
    "        y_valid.append(tag_label) \n",
    "        # Just a simple counter of the number of ones to cofirm with known number of dog images\n",
    "        if tag_label == 1:\n",
    "            count_dogs += 1\n",
    "        check += 1\n",
    "        # Only display load status a few times throughout the entire pre-process\n",
    "        if check % 10000 == 0:\n",
    "            print('path: ', path)\n",
    "            print('image_id: ', image_id)\n",
    "            print('No. of Dog labels so far: ', count_dogs) # No. of target labels/tags equal to one\n",
    "            print('Length X_valid: ', len(X_valid)) # Length of list of images\n",
    "            print()\n",
    "    # Display final outcome of pre-processing\n",
    "    print('Total No. of Dog labels: ', count_dogs) # No. of target labels/tags equal to one\n",
    "    print('Final Length X_valid: ', len(X_valid)) # Length of list of images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dump Training data to .pkl (binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving binary X_train to pkl...\n",
      "Saving binary y_train to pkl...\n",
      "\n",
      "Training data Pickled!\n"
     ]
    }
   ],
   "source": [
    "# Save X_train and y_train arrays as pkl files in assets folder (just outside of Github repo) to load in Notebook 3\n",
    "print('Saving binary X_train to pkl...')\n",
    "# Save X_train and y_train arrays as pkl files in assets folder (just outside of Github repo) to load in Notebook 3\n",
    "with open('../../assets/X_training_image_data.pkl', 'wb') as outfile:\n",
    "    pickle.dump(X_train, outfile, pickle.DEFAULT_PROTOCOL)\n",
    "    \n",
    "print('Saving binary y_train to pkl...')\n",
    "with open('../../assets/y_training_labels.pkl', 'wb') as outfile:\n",
    "    pickle.dump(y_train, outfile, pickle.DEFAULT_PROTOCOL)\n",
    "print()\n",
    "print('Training data Pickled!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dump Validation data to .pkl (binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving binary X_valid to pkl...\n",
      "Saving binary y_valid to pkl...\n",
      "\n",
      "Validation data Pickled!\n"
     ]
    }
   ],
   "source": [
    "# Save X_valid and y_valid arrays as pkl files in assets folder (just outside of Github repo) to load in Notebook 3\n",
    "print('Saving binary X_valid to pkl...')\n",
    "# Save X_valid and y_valid arrays as pkl files in assets folder (just outside of Github repo) to load in Notebook 3\n",
    "with open('../../assets/X_validation_image_data.pkl', 'wb') as outfile:\n",
    "    pickle.dump(X_valid, outfile, pickle.DEFAULT_PROTOCOL)\n",
    "    \n",
    "print('Saving binary y_valid to pkl...')\n",
    "with open('../../assets/y_validation_labels.pkl', 'wb') as outfile:\n",
    "    pickle.dump(y_valid, outfile, pickle.DEFAULT_PROTOCOL)\n",
    "print()\n",
    "print('Validation data Pickled!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "361280"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.getsizeof(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "578928"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.getsizeof(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that all is copacetic with train set\n",
    "print('X_train:')\n",
    "print(f'\\tLength: {len(X_train)}\\n\\\n",
    "        DType: {type(X_train)}\\n\\\n",
    "        Element Shapes: {X_train[0].shape}\\n\\\n",
    "        Element DTypes: {type(X_train[0])}\\n')\n",
    "\n",
    "# Show pic\n",
    "plt.figure(figsize = (8, 8)); \n",
    "plt.imshow(X_train[2766], aspect='auto');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How to find the correct image(the ith element of X_valid) associated with the known Image ID:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 43,733 images with IDs beyond range(43_733) --> image_data = X_valid[i]\n",
    "image_id = 2378691\n",
    "for i in range(len(X_valid)):\n",
    "    # 2nd element in each paths1 or paths2 tuple is an 'image_id'\n",
    "    # X & y created from paths1 or paths2 --> image_id = int(paths2[i][1])image_id\n",
    "    if int(paths2[i][1]) == image_id:\n",
    "        print(f'Image Index: {i}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How to find the correct image associated with the known image index in X_valid or y_valid\n",
    "image_index = 2761\n",
    "print(f'Image ID: {int(paths2[image_index][1])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.0\n"
     ]
    }
   ],
   "source": [
    "print(pickle.format_version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(\n",
    "            obj,\n",
    "            file,\n",
    "            protocol=None,\n",
    "            *,\n",
    "            fix_imports=True,\n",
    "            buffer_callback=None,\n",
    "        )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "conda-env-dsi-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
