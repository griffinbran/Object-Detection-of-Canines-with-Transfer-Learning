{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Collection and Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installs without warnings in conda env: dsi\n",
    "#!pip install visual_genome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import json\n",
    "from zipfile import ZipFile\n",
    "# Import OpenCV(cv2 module)\n",
    "import cv2\n",
    "# Import Python's standard utility module 'os' for interacting with Operating System\n",
    "import os\n",
    "# Import the Python wrapper for the VG API\n",
    "from visual_genome import api"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run cell only once to retrieve all image ID's from Visual Genome API and then store as a txt file for future reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve an array of integers representing all VG image ID's from API\n",
    "image_ids = api.get_all_image_ids()\n",
    "\n",
    "# Save array as txt file to bypass API next time\n",
    "with open('../data/image_ids.txt', 'w') as imagehandles:\n",
    "    imagehandles.writelines(\"%s\\n\" % ids for ids in image_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(108077, list, '1', str)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load Image ID's from text file\n",
    "with open('../data/image_ids.txt', 'r') as imagehandles:\n",
    "    # Store Image ID's as variable for image pre-processing, removing the endline character in the process\n",
    "    image_ids = [image_id[:-1] for image_id in imagehandles]\n",
    "# Check that all is copacetic\n",
    "len(image_ids), type(image_ids), image_ids[0], type(image_ids[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The processing method provided by the Visual Genome API, using relation mappings, is too slow to be effective in obtaining the object descriptions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of Images in dataset: 108,077 stored in \"json_objects\", a <class 'list'> of <class 'dict'>s\n"
     ]
    }
   ],
   "source": [
    "# Read objects.json file from Visual Genome, to retrieve the object data for each image\n",
    "with open('../../objects.json', 'r') as objects_json_file:\n",
    "    # Store a list of len(json_objects) = 108_077 dictionaries representing image object data\n",
    "    json_objects = json.load(objects_json_file)\n",
    "print(f'No. of Images in dataset: {len(json_objects):,} stored in \"json_objects\", a {type(json_objects)} of {type(json_objects[0])}s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of dog images in VG dataset: 3235\n"
     ]
    }
   ],
   "source": [
    "# loop thru each item in list\n",
    "dog_pic_ids = []\n",
    "for image_index in range(len(json_objects)):\n",
    "    # Number of objects\n",
    "    # len(json_objects[image_index]) = 3\n",
    "    # json_objects[image_index].keys() = dict_keys(['image_id', 'objects', 'image_url'])\n",
    "    num_objects = len(json_objects[image_index]['objects'])\n",
    "    # loop through objects_index searching for dog objects\n",
    "    objects_index = 0\n",
    "    # Objects_index lives in range(num_objects)\n",
    "    while objects_index < num_objects:\n",
    "        # Save image_id's of images with dogs\n",
    "        if json_objects[image_index]['objects'][objects_index][ 'names' ] == [  'dog'  ]:\n",
    "      # if json_objects[image_index]['objects'][objects_index]['synsets'] == ['dog.n.01']:\n",
    "    #####NOTICE: INSERT HOT DOG FILTER HERE LOL!\n",
    "            # Save image_id's of images with dogs\n",
    "            image_id = json_objects[image_index]['image_id']\n",
    "            dog_pic_ids.append(image_id)\n",
    "            # Escape 'while-loop' as soon as 'dog'-object found\n",
    "            objects_index = num_objects\n",
    "        else:\n",
    "            # Move on to next object in image, continue searching\n",
    "            objects_index += 1\n",
    "# Check how many dog pics were discovered in the dataset\n",
    "print(f'Total number of dog images in VG dataset: {len(dog_pic_ids)}')\n",
    "# Save dog_pic_ids as txt file to bypass loading object data from json next time\n",
    "with open('../data/dog_pic_ids.txt', 'w') as imagehandles:\n",
    "    imagehandles.writelines(\"%s\\n\" % ids for ids in dog_pic_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Identify and store dog pic image ID's specific to VG Part 2 Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Dog Pics in VG Part 2 Dataset: 1240\n"
     ]
    }
   ],
   "source": [
    "# NOTICE CODE FROM\n",
    "# https://thispointer.com/python-how-to-get-the-list-of-all-files-in-a-zip-archive/\n",
    "\n",
    "# Prepare to store dog pic image ID's in VG Part 2 Dataset\n",
    "dog_data_part2 = []\n",
    "\n",
    "# ~5.5 GB ZIP Archive, 40% of total data set\n",
    "with ZipFile('../../visual_genome_part2.zip', \"r\") as z:\n",
    "    # One file in zip archive\n",
    "    VG_100K_2 = z.namelist()\n",
    "\n",
    "    # Iterate over image file names, 'VG_100K_2/image_id.jpg'\n",
    "    for ith_image in VG_100K_2: \n",
    "        # Get extension of file, '.jpg'\n",
    "        ext = os.path.splitext(ith_image)[-1]\n",
    "        # Get root of file, root = VG_100K_2/image_id.jpg\n",
    "        root = os.path.splitext(ith_image)[0]\n",
    "        \n",
    "        # Skip over Archive Directory\n",
    "        if (ext == \".jpg\"):\n",
    "            # Skip root[:10]='VG_100K_2' in dog_pic_ids\n",
    "            if int(root[10:]) in dog_pic_ids:\n",
    "                dog_data_part2.append(int(root[10:]))\n",
    "                \n",
    "# Display percent of total dog images that live in VG Part 2 dataset\n",
    "print(f'Number of Dog Pics in VG Part 2 Dataset: {len(dog_data_part2)}')\n",
    "\n",
    "# Save dog_data_part2 as txt file to load in model tuning notebook\n",
    "with open('../data/dog_data_part2.txt', 'w') as imagehandles:\n",
    "    imagehandles.writelines(\"%s\\n\" % ids for ids in dog_data_part2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dog_pics_objs_dict2 = []\n",
    "for objects in range(len(json_objects)):\n",
    "    for dog in dog_data_part2:\n",
    "        if json_objects[objects]['image_id'] == dog:\n",
    "            dog_pics_objs_dict2.append(json_objects[objects])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1419\n",
      "1419\n"
     ]
    }
   ],
   "source": [
    "dogject_ids = []\n",
    "for image_idx in range(len(dog_pics_objs_dict2)):\n",
    "    for object_idx in range(len(dog_pics_objs_dict2[image_idx]['objects'])):\n",
    "        if dog_pics_objs_dict2[image_idx]['objects'][object_idx]['synsets'] == ['dog.n.01']:\n",
    "            dogject_ids.append(dog_pics_objs_dict2[image_idx]['objects'][object_idx]['object_id'])\n",
    "print(len(dogject_ids))\n",
    "print(len(set(dogject_ids)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dogject_ids.sort()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Identify and store dog pic image ID's specific to VG Part 1 Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Dog Pics in VG Part 1 Dataset: 1995\n"
     ]
    }
   ],
   "source": [
    "dog_data_part1 = []\n",
    "for image_id in dog_pic_ids:\n",
    "    if image_id not in dog_data_part2:\n",
    "        dog_data_part1.append(image_id)\n",
    "print(f'Number of Dog Pics in VG Part 1 Dataset: {len(dog_data_part1)}')\n",
    "\n",
    "# Save dog_data_part2 as txt file to load in model tuning notebook\n",
    "with open('../data/dog_data_part1.txt', 'w') as imagehandles:\n",
    "    imagehandles.writelines(\"%s\\n\" % ids for ids in dog_data_part1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dog pics in each VG dataset identified\n"
     ]
    }
   ],
   "source": [
    "# Check that all  is copacetic\n",
    "if len(dog_data_part1) + len(dog_data_part2) == len(dog_pic_ids):\n",
    "    print('Dog pics in each VG dataset identified')\n",
    "else:\n",
    "    print('Something is wrong')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent of Dog Pics in VG Part 1 Dataset: 61.67%\n",
      "Percent of Dog Pics in VG Part 2 Dataset: 38.33%\n"
     ]
    }
   ],
   "source": [
    "# Display percent of total dog images that live in VG Part 1 dataset\n",
    "print(f'Percent of Dog Pics in VG Part 1 Dataset: {100*len(dog_data_part1)/len(dog_pic_ids):.2f}%')\n",
    "\n",
    "# Display percent of total dog images that live in VG Part 2 dataset\n",
    "print(f'Percent of Dog Pics in VG Part 2 Dataset: {100*len(dog_data_part2)/len(dog_pic_ids):.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display ****ALL**** Dog Images in Visual Genome Part 2 Dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTICE CODE FROM\n",
    "# https://thispointer.com/python-how-to-get-the-list-of-all-files-in-a-zip-archive/\n",
    "\n",
    "# ~5.5 GB ZIP Archive, 40% of total data set\n",
    "with ZipFile('../../visual_genome_part2.zip', \"r\") as z:\n",
    "    # One file in zip archive\n",
    "    VG_100K_2 = z.namelist()\n",
    "\n",
    "    # Iterate over image file names, 'VG_100K_2/image_id.jpg'\n",
    "    for ith_image in VG_100K_2: \n",
    "        # Get extension of file, '.jpg'\n",
    "        ext = os.path.splitext(ith_image)[-1]\n",
    "        # Get root of file, root = VG_100K_2/image_id.jpg\n",
    "        root = os.path.splitext(ith_image)[0]\n",
    "        \n",
    "        # Skip over Archive Directory\n",
    "        if (ext == \".jpg\"):\n",
    "            # Skip root[:10]='VG_100K_2' in dog_pic_ids\n",
    "            if int(root[10:]) in dog_pic_ids:\n",
    "                # Read image binary data of 'VG_100K_2' from zip archive('visual_genome_part2.zip')\n",
    "                in_bytes = z.read(ith_image) # VG_100K_2/\n",
    "                # Decode bytes to image\n",
    "                img = cv2.imdecode(np.frombuffer(in_bytes, np.uint8), cv2.IMREAD_COLOR)\n",
    "    \n",
    "                # Output img with window name as 'image' \n",
    "################# WARNING WARNING WARNING: Running this cell with the following line uncommented will require force kernel restart\n",
    "################# Unless you wait for all images (1240 images * 1 sec hold > 20 minutes!)\n",
    "                #cv2.imshow('img', img)\n",
    "                # Display for 1sec = 1_000ms\n",
    "                #cv2.waitKey(1000)\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hot Dog filter clearly needed after browsing all pphotos, maybe 6-10 images are actually just hot dogs\n",
    "#for dog in dog_pic_ids:\n",
    "    # Consider what "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output from first three iterations:\n",
      "\n",
      "d = 10.jpg\n",
      "Training LABELS:  {10}\n",
      "Training paths:  [('../../visual_genome_part1/VG_100K_1/10.jpg', '10', 0)]\n",
      "\n",
      "d = 107899.jpg\n",
      "Training LABELS:  {10, 107899}\n",
      "Training paths:  [('../../visual_genome_part1/VG_100K_1/10.jpg', '10', 0), ('../../visual_genome_part1/VG_100K_1/107899.jpg', '107899', 0)]\n",
      "\n",
      "d = 107900.jpg\n",
      "Training LABELS:  {10, 107899, 107900}\n",
      "Training paths:  [('../../visual_genome_part1/VG_100K_1/10.jpg', '10', 0), ('../../visual_genome_part1/VG_100K_1/107899.jpg', '107899', 0), ('../../visual_genome_part1/VG_100K_1/107900.jpg', '107900', 0)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Path to Training data\n",
    "BASEPATH1 = '../../visual_genome_part1/VG_100K_1/'\n",
    "# Path to Validation data\n",
    "BASEPATH2 = '../../visual_genome_part2/VG_100K_2/'\n",
    "\n",
    "# Images in Train set: Part 1 \n",
    "LABELS1 = set() # {set of integers of image_ids }\n",
    "paths1 = [] # [List of tuples ('string of full image path + file name', 'image_id')...(64_344 out of 108_077 tuples/images) ]\n",
    "\n",
    "# Images in Validation set: Part 2 {set of integers of image_ids }\n",
    "LABELS2 = set() # {set of integers of image_ids }\n",
    "paths2 = [] # [List of tuples ('string of full image path + file name', 'image_id')...(43_733 out of 108_077 tuples/images) ]\n",
    "\n",
    "# For the Training Data\n",
    "print('Output from first 03 iterations thru training dataset for paths1:\\n')\n",
    "check = 0\n",
    "\n",
    "for d in os.listdir(BASEPATH1):\n",
    "    LABELS1.add(int(d[:-4]))\n",
    "    if d[:-4] not in dog_data_part1:\n",
    "        paths1.append((BASEPATH1+d, d[:-4], 0))\n",
    "    elif d[:-4] in dog_data_part1:\n",
    "        paths1.append((BASEPATH1+d, d[:-4], 1))   \n",
    "    if check < 3:\n",
    "        print('d =', d)\n",
    "        print('Training LABELS: ', LABELS1)\n",
    "        print('Training paths: ', paths1)\n",
    "        print()\n",
    "        check += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# For the Validation Data\n",
    "print('Output from first 03 iterations thru validation dataset for paths2:\\n')\n",
    "check = 0\n",
    "\n",
    "for d in os.listdir(BASEPATH2):\n",
    "    LABELS2.add(int(d[:-4]))\n",
    "    if d[:-4] not in dog_data_part2:\n",
    "        paths2.append((BASEPATH2+d, d[:-4], 0))\n",
    "    elif d[:-4] in dog_data_part2:\n",
    "        paths2.append((BASEPATH2+d, d[:-4], 1))   \n",
    "    if check < 3:\n",
    "        print('d =', d)\n",
    "        print('Validation LABELS: ', LABELS2)\n",
    "        print('Validation paths: ', paths2)\n",
    "        print()\n",
    "        check += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output from first three iterations in training:\n",
      "\n",
      "path:  ../../visual_genome_part1/VG_100K_1/10.jpg\n",
      "image_id:  10\n",
      "tag_label:  0\n",
      "\n",
      "Properly Labeled Dog Pics (out of 1995): 0\n",
      "Properly Labeled Dogless Pics (out of 62,179):  64346\n"
     ]
    }
   ],
   "source": [
    "# Check that all is copacetic with the Training set labeling above\n",
    "count_dog_p1 = 0\n",
    "count_dogless_p1 = 0\n",
    "print('Output from first three iterations in training:\\n')\n",
    "check = 0\n",
    "for path, image_id, tag_label in paths1: # dtypes = ('str', 'str', int)\n",
    "    if tag_label == 1:\n",
    "        count_dog_p1 += 1\n",
    "    elif tag_label == 0:\n",
    "        count_dogless_p1 += 1\n",
    "    if check < 1:\n",
    "        print('path: ', path)\n",
    "        print('image_id: ', image_id)\n",
    "        print('tag_label: ', tag_label)\n",
    "        print()\n",
    "        check += 1\n",
    "print(f'Properly Labeled Dog Pics (out of 1995): {count_dog_p1}\\nProperly Labeled Dogless Pics (out of 62,179):  {count_dogless_p1}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function to prepare data for input to VGG-16 Network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resizing and converting to RGB\n",
    "def load_and_preprocess_image(path):\n",
    "    image = cv2.imread(path)\n",
    "    image = cv2.resize(image, (224,224))\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The code in the cell below will first check for an existing X_valid array of processed data stored in .txt files\n",
    "> * If the try results in a FinalNotFoundError, X-images and y-labels arrays will be created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HEADS UP: Could not load taining images/labels from .txt files...\n",
      "                \t...hold on for ~10-15 mins while X and y are prepared\n",
      "\n",
      "path:  ../../visual_genome_part1/VG_100K_1/2322741.jpg\n",
      "image_id:  2322741\n",
      "No. of Dog labels so far:  0\n",
      "Length X_train:  10000\n",
      "\n",
      "path:  ../../visual_genome_part1/VG_100K_1/2333207.jpg\n",
      "image_id:  2333207\n",
      "No. of Dog labels so far:  0\n",
      "Length X_train:  20000\n",
      "\n",
      "path:  ../../visual_genome_part1/VG_100K_1/2343671.jpg\n",
      "image_id:  2343671\n",
      "No. of Dog labels so far:  0\n",
      "Length X_train:  30000\n",
      "\n",
      "path:  ../../visual_genome_part1/VG_100K_1/2354151.jpg\n",
      "image_id:  2354151\n",
      "No. of Dog labels so far:  0\n",
      "Length X_train:  40000\n",
      "\n",
      "path:  ../../visual_genome_part1/VG_100K_1/2364610.jpg\n",
      "image_id:  2364610\n",
      "No. of Dog labels so far:  0\n",
      "Length X_train:  50000\n",
      "\n",
      "path:  ../../visual_genome_part1/VG_100K_1/2375066.jpg\n",
      "image_id:  2375066\n",
      "No. of Dog labels so far:  0\n",
      "Length X_train:  60000\n",
      "\n",
      "Total No. of Dog labels:  0\n",
      "Final Length X_train:  64346\n",
      "Wall time: 24min 31s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Load target labels for training data set\n",
    "try:\n",
    "    with open('../../assets/y_training_labels.txt', 'r') as trainlabels:\n",
    "        # Store training images as variable for loading into model for scoring\n",
    "        y_train_loaded = np.array([train_image_label for train_image_label in trainlabels])\n",
    "\n",
    "    # Load feature matrix of training images from text file\n",
    "    with open('../../assets/X_training_image_data.txt', 'r') as trainimages:\n",
    "        # Store training images as variable for loading into model for scoring\n",
    "        X_train_loaded = np.array([processed_image for processed_image in trainimages])\n",
    "\n",
    "    # Check that all is copacetic\n",
    "    len(X_train), type(dog_data_part1), dog_data_part1[0], type(dog_data_part1[0])\n",
    "    # No. of target labels/tags equal to one\n",
    "    print('Final No. of Dog labels in training set: ', count_dogs) \n",
    "    # Length of list of images\n",
    "    print('Final Length X_train: ', len(X_train)) \n",
    "# Just in case the data can be loaded from text, we want to know!\n",
    "except FileNotFoundError:\n",
    "    print('HEADS UP: Could not load taining images/labels from .txt files...\\n\\\n",
    "                \\t...hold on for ~10-15 mins while X and y are prepared')\n",
    "    print()\n",
    "    # Build a feature matrix \n",
    "    X_train = []\n",
    "    y_train = []\n",
    "    check = 0\n",
    "    count_dogs = 0\n",
    "    # Recall that paths1 and paths2 have 3-tuple info for each image in dataset\n",
    "    for  path, image_id, tag_label in paths1:  # dtypes = ('str', 'str', int)\n",
    "        #for image_path in os.listdir(path):\n",
    "        image = load_and_preprocess_image(path)\n",
    "         # X[image_index] image corresponds to image_id = paths1[image_index][1]\n",
    "        X_train.append(image)\n",
    "        # y[image_index] label corresponds to image_id = paths1[image_index][1]\n",
    "        y_train.append(tag_label) \n",
    "        # Just a simple counter of the number of ones to cofirm with known number of dog images\n",
    "        if tag_label == 1:\n",
    "            count_dogs += 1\n",
    "        check += 1\n",
    "        # Only display load status a few times throughout the entire pre-process\n",
    "        if check % 10000 == 0:\n",
    "            print('path: ', path)\n",
    "            print('image_id: ', image_id)\n",
    "            print('No. of Dog labels so far: ', count_dogs) # No. of target labels/tags equal to one\n",
    "            print('Length X_train: ', len(X_train)) # Length of list of images\n",
    "            print()\n",
    "    # Display final outcome of pre-processing\n",
    "    print('Total No. of Dog labels: ', count_dogs) # No. of target labels/tags equal to one\n",
    "    print('Final Length X_train: ', len(X_train)) # Length of list of images\n",
    "    # Save X_train and y_train arrays as txt files in assets folder (just outside of Github repo) to load in Notebook 3\n",
    "    with open('../../assets/X_training_image_data.txt', 'w') as trainimages:\n",
    "        trainimages.writelines(\"%s\\n\" % img for img in X_train)\n",
    "    with open('../../assets/y_training_labels.txt', 'w') as trainimages:\n",
    "        trainimages.writelines(\"%s\\n\" % img for img in y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that all is copacetic with train set\n",
    "print('X_train:')\n",
    "print(f'\\tLength: {len(X_train)}\\n\\\n",
    "        DType: {type(X_train)}\\n\\\n",
    "        Element Shapes: {X_train[0].shape}\\n\\\n",
    "        Element DTypes: {type(X_train[0])}\\n')\n",
    "\n",
    "# Show pic\n",
    "plt.figure(figsize = (8, 8)); \n",
    "plt.imshow(X_train[2766], aspect='auto');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How to find the correct image(the ith element of X_valid) associated with the known Image ID:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 43,733 images with IDs beyond range(43_733) --> image_data = X_valid[i]\n",
    "image_id = 2378691\n",
    "for i in range(len(X_valid)):\n",
    "    # 2nd element in each paths1 or paths2 tuple is an 'image_id'\n",
    "    # X & y created from paths1 or paths2 --> image_id = int(paths2[i][1])image_id\n",
    "    if int(paths2[i][1]) == image_id:\n",
    "        print(f'Image Index: {i}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How to find the correct image associated with the known image index in X_valid or y_valid\n",
    "image_index = 2761\n",
    "print(f'Image ID: {int(paths2[image_index][1])}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:dsi]",
   "language": "python",
   "name": "conda-env-dsi-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
