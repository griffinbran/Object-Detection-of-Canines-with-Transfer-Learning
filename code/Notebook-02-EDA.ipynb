{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notebook 02: EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import neccessary support\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2, os\n",
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import shuffle\n",
    "from zipfile import ZipFile\n",
    "\n",
    "#import matplotlib.image as mpimg\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "# load VGG-16 model: 23 layers, 138,357,544 params, 528MB\n",
    "from keras.applications.vgg16 import VGG16\n",
    "# These models expect \n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input, decode_predictions\n",
    "from keras.utils.vis_utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1240, list, '2377385', str)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load Image ID's from text file\n",
    "with open('../data/dog_data_part2.txt', 'r') as imagehandles:\n",
    "    # Store Image ID's as variable for image pre-processing, removing the endline character in the process\n",
    "    dog_data_part2 = [image_id[:-1] for image_id in imagehandles]\n",
    "# Check that all is copacetic\n",
    "len(dog_data_part2), type(dog_data_part2), dog_data_part2[0], type(dog_data_part2[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.1\n",
      "Please install GPU version of TF\n"
     ]
    }
   ],
   "source": [
    "# Sometimes my tensorflow tries to use GPU support but I don't want it to, have had many errors.\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "import tensorflow as tf\n",
    "#tf.compat.v1.Session(), .compat.v1.\n",
    "sess_cpu = tf.compat.v1.Session(config=tf.compat.v1.ConfigProto(device_count={'GPU': 0}))\n",
    "print(tf.__version__)\n",
    "if tf.test.gpu_device_name():\n",
    "    print('Default GPU Device:{}'.format(tf.test.gpu_device_name()))\n",
    "else:\n",
    "    print(\"Please install GPU version of TF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please install GPU version of TF\n"
     ]
    }
   ],
   "source": [
    "if tf.test.gpu_device_name():\n",
    "    print('Default GPU Device:{}'.format(tf.test.gpu_device_name()))\n",
    "else:\n",
    "    print(\"Please install GPU version of TF\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiate VGG-16 Model<br>\n",
    ">  Image data format: Set in Keras JSON config file<br>\n",
    "> - Stored at  '~/.keras/keras.json'<br>\n",
    "{<br>\n",
    "    \"floatx\": \"float32\",<br>\n",
    "    \"epsilon\": 1e-07,<br>\n",
    "    \"backend\": \"tensorflow\",<br>\n",
    "    \"image_data_format\": \"channels_last\"<br>\n",
    "}<br><br>\n",
    "- NOTE: \"Channels Last = (height, width, depth)-TensorFlow data format convention<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vizualize filters and feature maps of CNNs with VGG-16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 4096)              102764544 \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "predictions (Dense)          (None, 1000)              4097000   \n",
      "=================================================================\n",
      "Total params: 138,357,544\n",
      "Trainable params: 138,357,544\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# load VGG-16 model: 23 layers, 138,357,544 params, 528MB\n",
    "from keras.applications.vgg16 import VGG16\n",
    "\n",
    "# Adjust input size of the model for include_top=False\n",
    "# new_input = Input(shape=(224,224,3)) --> MUST INCLUDE THIS PARAM AFTER CLASSIFICATION\n",
    "\n",
    "# load the model weights into memory\n",
    "# https://keras.io/api/applications/vgg/#vgg16-function\n",
    "model_vgg16 = VGG16(weights='imagenet')\n",
    "#model_vgg16 = VGG16(\n",
    "#                include_top=True,   # include_top=False to load model wihtout the fully-connected output layers used to make predictions\n",
    "#                weights='imagenet', # Weights are downloaded automatically when instantiating a model: Keras Applications ~/.keras/models/\n",
    "#                input_tensor=None,  # input_tensor = new_input = Input(shape=(224,224,3))\n",
    "#                input_shape=None,\n",
    "#                pooling=None,\n",
    "#                classes=1000,\n",
    "#                classifier_activation=\"softmax\"\n",
    "#            )\n",
    "# Summarize the loaded model with all layers (include_top=True)\n",
    "model_vgg16.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filter Summary (by network layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer Summary\tKernel Size: ( K x K )\t\n",
      "\n",
      "Number\t\tName\t\t(K, K, Depth, Nodes)\n",
      "Layer 1:\tblock1_conv1\t(3, 3, 3, 64)\n",
      "Layer 2:\tblock1_conv2\t(3, 3, 64, 64)\n",
      "Layer 4:\tblock2_conv1\t(3, 3, 64, 128)\n",
      "Layer 5:\tblock2_conv2\t(3, 3, 128, 128)\n",
      "Layer 7:\tblock3_conv1\t(3, 3, 128, 256)\n",
      "Layer 8:\tblock3_conv2\t(3, 3, 256, 256)\n",
      "Layer 9:\tblock3_conv3\t(3, 3, 256, 256)\n",
      "Layer 11:\tblock4_conv1\t(3, 3, 256, 512)\n",
      "Layer 12:\tblock4_conv2\t(3, 3, 512, 512)\n",
      "Layer 13:\tblock4_conv3\t(3, 3, 512, 512)\n",
      "Layer 15:\tblock5_conv1\t(3, 3, 512, 512)\n",
      "Layer 16:\tblock5_conv2\t(3, 3, 512, 512)\n",
      "Layer 17:\tblock5_conv3\t(3, 3, 512, 512)\n",
      "Layer 20:\tfc1\t(25088, 4096)\n",
      "Layer 21:\tfc2\t(4096, 4096)\n",
      "\n",
      "Layer 1: (3, 3, 3, 64)\n"
     ]
    }
   ],
   "source": [
    "# VGG-16 Layers with non-zero parameters\n",
    "layers_VGG16 = [ 1, 2, 4, 5, 7, 8, 9, 11, 12, 13, 15, 16, 17, 20, 21, 22 ]\n",
    "# Choose a layer to perform feature extraction\n",
    "layer_VGG16  = 0\n",
    "# summarize filter shapes\n",
    "print('Layer Summary\\tKernel Size: ( K x K )\\t')\n",
    "print()\n",
    "print('Number\\t\\tName\\t\\t(K, K, Depth, Nodes)')\n",
    "# Loop thru each layer in ImageNet Model to summarize\n",
    "for layer in model_vgg16.layers:\n",
    "    # check for convolutional layer\n",
    "    if ('conv' not in layer.name) & ('fc' not in layer.name):\n",
    "        layer_VGG16 += 1\n",
    "        continue # Exclude fully connected layers & return to loop beginning\n",
    "    # get filter weights\n",
    "    filters, biases = layer.get_weights()\n",
    "    print(f'Layer {layer_VGG16}:\\t{layer.name}\\t{filters.shape}')\n",
    "    layer_VGG16 += 1\n",
    "print()\n",
    "\n",
    "# Select layer from VGG-16 layers list above to retrieve weights\n",
    "layer_number = layers_VGG16[0]\n",
    "# Retrieve current weights from selected hidden layer: 'layer_number'\n",
    "# Weights rep state of layer, get_weights loads state into similarly parameterized layers\n",
    "filters_extract, biases_extract = model_vgg16.layers[layer_number].get_weights()\n",
    "print(f'Layer {layer_number}: {filters_extract.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[0.8601116 , 0.6161919 , 0.55114007, ..., 0.4212452 ,\n",
       "          0.4828852 , 0.5304859 ],\n",
       "         [0.9545779 , 0.5408773 , 0.6017826 , ..., 0.4582953 ,\n",
       "          0.4846108 , 0.5538601 ],\n",
       "         [0.89960235, 0.3896376 , 0.5539096 , ..., 0.42523453,\n",
       "          0.4852669 , 0.5518304 ]],\n",
       "\n",
       "        [[0.81635594, 0.65118545, 0.52590066, ..., 0.4087713 ,\n",
       "          0.340725  , 0.47531587],\n",
       "         [0.8683965 , 0.5615535 , 0.5647105 , ..., 0.44733417,\n",
       "          0.2931476 , 0.46953422],\n",
       "         [0.8437643 , 0.39145148, 0.5206881 , ..., 0.42896524,\n",
       "          0.30857468, 0.4940327 ]],\n",
       "\n",
       "        [[0.47662497, 0.63058364, 0.43417358, ..., 0.4150598 ,\n",
       "          0.22949417, 0.28977698],\n",
       "         [0.4609779 , 0.5572666 , 0.4450579 , ..., 0.4508793 ,\n",
       "          0.12949093, 0.22478487],\n",
       "         [0.4736674 , 0.40397066, 0.41671643, ..., 0.42346177,\n",
       "          0.16341406, 0.27143562]]],\n",
       "\n",
       "\n",
       "       [[[0.7392438 , 0.6404719 , 0.6507926 , ..., 0.43525034,\n",
       "          0.810127  , 0.7901605 ],\n",
       "         [0.7946921 , 0.5488246 , 0.7126644 , ..., 0.4703888 ,\n",
       "          0.86608565, 0.84737706],\n",
       "         [0.767142  , 0.37799242, 0.65472686, ..., 0.44734278,\n",
       "          0.84025717, 0.8312743 ]],\n",
       "\n",
       "        [[0.55478704, 0.6826218 , 0.6467724 , ..., 0.48393103,\n",
       "          0.7254765 , 0.81496185],\n",
       "         [0.55631167, 0.5759833 , 0.69669527, ..., 0.5216048 ,\n",
       "          0.73505795, 0.8445131 ],\n",
       "         [0.5637889 , 0.38582882, 0.6426892 , ..., 0.51357675,\n",
       "          0.7271578 , 0.8556534 ]],\n",
       "\n",
       "        [[0.23765364, 0.6508931 , 0.45429817, ..., 0.41053838,\n",
       "          0.31218964, 0.3372736 ],\n",
       "         [0.17024457, 0.56070673, 0.47241867, ..., 0.44369915,\n",
       "          0.25439772, 0.29604584],\n",
       "         [0.20940173, 0.3883068 , 0.43874004, ..., 0.42636505,\n",
       "          0.27921656, 0.3426477 ]]],\n",
       "\n",
       "\n",
       "       [[[0.47966576, 0.6256226 , 0.53464687, ..., 0.41405112,\n",
       "          0.7129372 , 0.560162  ],\n",
       "         [0.47875416, 0.5493164 , 0.58391243, ..., 0.4425156 ,\n",
       "          0.78985673, 0.6016313 ],\n",
       "         [0.48481962, 0.39486766, 0.5367759 , ..., 0.40757152,\n",
       "          0.7642704 , 0.5935313 ]],\n",
       "\n",
       "        [[0.31966972, 0.65861547, 0.52460825, ..., 0.42867762,\n",
       "          0.7157403 , 0.56620234],\n",
       "         [0.2662131 , 0.56731075, 0.5625993 , ..., 0.45979398,\n",
       "          0.7554137 , 0.58273125],\n",
       "         [0.3017171 , 0.39434877, 0.51834106, ..., 0.4387944 ,\n",
       "          0.74270797, 0.59851784]],\n",
       "\n",
       "        [[0.25103468, 0.63294035, 0.42663756, ..., 0.40495452,\n",
       "          0.41524813, 0.3174621 ],\n",
       "         [0.145611  , 0.55763006, 0.43700036, ..., 0.43213305,\n",
       "          0.3940431 , 0.27279767],\n",
       "         [0.19757837, 0.40186328, 0.40804785, ..., 0.4020266 ,\n",
       "          0.41293785, 0.31385297]]]], dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filters_extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3, 3, 3, 64), numpy.ndarray)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (kernel-height, kernel-width, channel-depth, No. of filters)\n",
    "# 64-filters each (3 x 3 x 3) 3D volume, cubic filters\n",
    "filters_extract.shape, type(filters_extract)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3, 64),\n",
       " array([[[-0.36283946, -0.48702785, -0.45139903],\n",
       "         [-0.39102998, -0.495031  , -0.46935585],\n",
       "         [-0.3776668 , -0.50566256, -0.4622438 ]],\n",
       " \n",
       "        [[-0.37709406, -0.4805826 , -0.44129026],\n",
       "         [-0.43290257, -0.46505883, -0.43076617],\n",
       "         [-0.51870257, -0.67140007, -0.6122331 ]],\n",
       " \n",
       "        [[-0.38299575, -0.48918396, -0.45314637],\n",
       "         [-0.40317345, -0.5517545 , -0.46822482],\n",
       "         [-0.38670486, -0.5010919 , -0.45361367]]], dtype=float32))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filters_extract[0][0].shape, filters_extract.min(3),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.42947057, 0.55037946, 0.4800154 ],\n",
       "        [0.50021327, 0.6085159 , 0.5649865 ],\n",
       "        [0.42510888, 0.57510966, 0.51294214]],\n",
       "\n",
       "       [[0.36549452, 0.43711686, 0.40405855],\n",
       "        [0.48986775, 0.52829504, 0.5055312 ],\n",
       "        [0.44455817, 0.5295403 , 0.4862477 ]],\n",
       "\n",
       "       [[0.32685903, 0.4086302 , 0.37457848],\n",
       "        [0.459542  , 0.53946865, 0.5184412 ],\n",
       "        [0.40483335, 0.454858  , 0.40707463]]], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " filters_extract.max(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize Second Layer (First Conv2D Layer immediately following the input layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLayer 1:  FILTER #\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 12 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# normalize filter values to 0-1 so we can visualize them\n",
    "f_min, f_max = filters_extract.min(), filters_extract.max()\n",
    "# Sets the minimum to zero and the maximum to one\n",
    "filters_extract = (filters_extract - f_min) / (f_max - f_min)\n",
    "\n",
    "# plot first few filters\n",
    "n_filters, ix = 4, 1\n",
    "for i in range(n_filters):\n",
    "    # get the filter\n",
    "    f = filters_extract[:, :, :, i]\n",
    "    # plot each channel separately\n",
    "    for j in range(3):\n",
    "        # specify subplot and turn of axis\n",
    "        if j == 0:\n",
    "            c = '\\nBLUE'\n",
    "            color_map = 'Blues'\n",
    "        elif j == 1:\n",
    "            c = '\\nGREEN'\n",
    "            color_map = 'Greens'\n",
    "        else:\n",
    "            c ='\\nRED'\n",
    "            color_map = 'Reds'\n",
    "        ax = plt.subplot(n_filters, 3, ix, fc='grey')\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        plt.xlabel(xlabel=c,color='w')\n",
    "        plt.ylabel(ylabel=f'  \\n\\n{i+1}',color='w',rotation=0)\n",
    "        # plot filter channel in grayscale\n",
    "        plt.imshow(f[:, :, j], cmap=color_map)\n",
    "        ix += 1\n",
    "#print('\\t\\t FILTER #')\n",
    "print(f'\\tLayer {layer_number}:  FILTER #')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Visual Genome Dog Data, chosen at random, on VGG-16 Loaded Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: (for random dog = 2392123) \n",
      "\n",
      "\t11.39%\t:maze\n",
      "\t8.13%\t:swimming_trunks\n",
      "\t5.47%\t:swing\n",
      "\t4.15%\t:fountain\n",
      "\t3.22%\t:snorkel\n"
     ]
    }
   ],
   "source": [
    "# NOTICE, SOME CODE IN THIS CELL FROM:\n",
    "# https://thispointer.com/python-how-to-get-the-list-of-all-files-in-a-zip-archive/\n",
    "\n",
    "# Input shape acrandom_dogby VGG-16 = 224 x 224 x3\n",
    "img_height = 224\n",
    "img_width = 224\n",
    "\n",
    "# Choose a dog randomly to test breed accuracy\n",
    "dog_pic_x = random.randint(0, len(dog_data_part2)-1)\n",
    "random_dog = int(dog_data_part2[dog_pic_x])\n",
    "\n",
    "# ~5.5 GB ZIP Archive, 40% of total data set\n",
    "# Open, read, and close ZIP file for faster image pre-processing\n",
    "with ZipFile('../../visual_genome_part2.zip', \"r\") as z:\n",
    "    # One file in zip archive\n",
    "    VG_100K_2 = z.namelist()\n",
    "\n",
    "    # Iterate over image file names, 'VG_100K_2/image_id.jpg'\n",
    "    for ith_image in VG_100K_2: \n",
    "        # Get extension of file, '.jpg'\n",
    "        ext = os.path.splitext(ith_image)[-1]\n",
    "        # Get root of file, root = VG_100K_2/image_id.jpg\n",
    "        root = os.path.splitext(ith_image)[0]\n",
    "        \n",
    "        # Skip over Archive Directory\n",
    "        if (ext == \".jpg\"):\n",
    "            \n",
    "            # Skip root[:10]='VG_100K_2' in dog_pic_ids\n",
    "            if int(root[10:]) == random_dog:\n",
    "                \n",
    "                # Read image binary data of 'VG_100K_2' from zip archive('visual_genome_part2.zip')\n",
    "                in_bytes = z.read(ith_image) # VG_100K_2/\n",
    "                # Decode bytes to image\n",
    "                img = cv2.imdecode(np.frombuffer(in_bytes, np.uint8), cv2.IMREAD_COLOR)\n",
    "                # Input shape accepted by VGG-16 = 224 x 224 x3\n",
    "                img = cv2.resize(img, dsize=(img_width, img_height))\n",
    "                # Convert a PIL image instance to a Numpy array\n",
    "                dog_x = image.img_to_array(img)\n",
    "                # Expand the shape of the array: Insert new axis at 'axis' position in expanded array shape\n",
    "                dog_x = np.expand_dims(dog_x, axis=0)\n",
    "                # Returns array with type: 'float32', covert: RGB --> BGR, & zero-center each channel wrt ImageNet dataset\n",
    "                # i.e. subtract mean RGB value, computed on Train set, from each pixel\n",
    "                dog_x = preprocess_input(dog_x)\n",
    "                \n",
    "                # Extract features from image_id = dog_x with VGG-16\n",
    "                # Get a prediction: Probability dog_x image belongs to each of the 1,000 object types from ImageNet\n",
    "                preds = model_vgg16.predict(dog_x)\n",
    "\n",
    "                # Decode extracted features into class, description, and probability\n",
    "                # Converts probabilities to class labels\n",
    "                preds_class_breed_score = decode_predictions(preds, top=5)[0]\n",
    "                \n",
    "                # Display the prediction corresponding to the image\n",
    "                print(f'Prediction: (for random dog = {random_dog}) \\n')\n",
    "                for i in range(len(preds_class_breed_score)):\n",
    "                    print(f'\\t{preds_class_breed_score[i][2]*100:.2f}%\\t:{preds_class_breed_score[i][1]}')\n",
    "\n",
    "                # Output img with window name as 'image' \n",
    "                cv2.imshow('img', img)\n",
    "                \n",
    "                # Display for 30 secs = 1_000ms * 30\n",
    "                #cv2.waitKey(30*1000)\n",
    "                \n",
    "                # Display image indefinitely\n",
    "                cv2.waitKey(0)\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "## model.save('/../assets/model.h5')\n",
    "\n",
    "print(\"Saved model to disk\")\n",
    "#del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: \n",
      "\n",
      "\t37.11%\t:keeshond\n",
      "\t13.47%\t:schipperke\n",
      "\t8.45%\t:Newfoundland\n",
      "\t7.30%\t:groenendael\n",
      "\t6.35%\t:Norwegian_elkhound\n",
      "\t3.85%\t:indri\n",
      "\t3.57%\t:skunk\n",
      "\t3.21%\t:Tibetan_mastiff\n",
      "\t1.63%\t:German_shepherd\n",
      "\t1.08%\t:Bouvier_des_Flandres\n",
      "\t0.93%\t:Border_collie\n",
      "\t0.93%\t:malamute\n",
      "\t0.68%\t:Siberian_husky\n",
      "\t0.64%\t:fur_coat\n",
      "\t0.48%\t:flat-coated_retriever\n",
      "\t0.47%\t:chow\n",
      "\t0.47%\t:kelpie\n",
      "\t0.45%\t:Pomeranian\n",
      "\t0.44%\t:Leonberg\n",
      "\t0.42%\t:Eskimo_dog\n",
      "\t0.29%\t:timber_wolf\n",
      "\t0.27%\t:American_black_bear\n",
      "\t0.24%\t:bearskin\n",
      "\t0.19%\t:llama\n",
      "\t0.18%\t:Scottish_deerhound\n"
     ]
    }
   ],
   "source": [
    "img_path = '../../visual_genome_part2/VG_100K_2/2405343.jpg'\n",
    "img = image.load_img(img_path, target_size=(224, 224))\n",
    "dog_x = image.img_to_array(img)\n",
    "dog_x = np.expand_dims(dog_x, axis=0)\n",
    "dog_x = preprocess_input(dog_x)\n",
    "\n",
    "# Extract features from image_id = dog_x with VGG-16\n",
    "# Get a prediction: Probability dog_x image belongs to each of the 1,000 object types from ImageNet\n",
    "preds = model_vgg16.predict(dog_x)\n",
    "\n",
    "# Decode extracted features into class, description, and probability\n",
    "# Specifically, converts probabilities to class labels\n",
    "preds_class_breed_score = decode_predictions(preds, top=25)[0] # top = n returns top-n most likely classes for given image\n",
    "print('Prediction: \\n')\n",
    "for i in range(len(preds_class_breed_score)):\n",
    "    print(f'\\t{preds_class_breed_score[i][2]*100:.2f}%\\t:{preds_class_breed_score[i][1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(numpy.ndarray, 1)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(preds), len(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Failed to import pydot. You must `pip install pydot` and install graphviz (https://graphviz.gitlab.io/download/), ', 'for `pydotprint` to work.')\n"
     ]
    }
   ],
   "source": [
    "# Creates an unneccessary plot of VGG-16 Model Layers, will install and check-out if there's time\n",
    "plot_model(model_vgg16, to_file='../images/vgg16.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASEPATH1 = '../../visual_genome_part1/VG_100K_1/'\n",
    "BASEPATH2 = '../../visual_genome_part2/VG_100K_2/'\n",
    "\n",
    "LABELS = set()\n",
    "\n",
    "paths = []\n",
    "    \n",
    "for d in os.listdir(BASEPATH2):\n",
    "    LABELS.add(int(d[:-4]))\n",
    "    paths.append((BASEPATH2+d, int(d[:-4])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resizing and converting to RGB\n",
    "def load_and_preprocess_image(path):\n",
    "    image = cv2.imread(path)\n",
    "    image = cv2.resize(image, (224,224))\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir('../../visual_genome_part2/VG_100K_2/');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../../visual_genome_part2/VG_100K_2/1.jpg'"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paths[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43733"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "y = []\n",
    "\n",
    "for path, label in paths:\n",
    "    #for image_path in os.listdir(path):\n",
    "    image = load_and_preprocess_image(path)\n",
    "    X.append(image)\n",
    "    y.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../../visual_genome_part2/VG_100K_2/2378352.jpg'"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[196, 203, 226],\n",
       "        [196, 202, 226],\n",
       "        [198, 204, 225],\n",
       "        ...,\n",
       "        [160, 170, 203],\n",
       "        [161, 170, 204],\n",
       "        [163, 173, 204]],\n",
       "\n",
       "       [[201, 206, 225],\n",
       "        [211, 215, 233],\n",
       "        [218, 223, 235],\n",
       "        ...,\n",
       "        [161, 169, 205],\n",
       "        [162, 170, 206],\n",
       "        [161, 170, 203]],\n",
       "\n",
       "       [[222, 225, 236],\n",
       "        [213, 216, 234],\n",
       "        [204, 207, 228],\n",
       "        ...,\n",
       "        [160, 168, 204],\n",
       "        [163, 169, 203],\n",
       "        [167, 173, 205]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 70,  69,  34],\n",
       "        [ 77,  78,  37],\n",
       "        [ 82,  79,  37],\n",
       "        ...,\n",
       "        [ 77,  82, 102],\n",
       "        [ 76,  79, 100],\n",
       "        [ 68,  74,  94]],\n",
       "\n",
       "       [[ 82,  78,  40],\n",
       "        [ 83,  82,  38],\n",
       "        [ 86,  83,  37],\n",
       "        ...,\n",
       "        [ 73,  78,  98],\n",
       "        [ 72,  78,  98],\n",
       "        [ 66,  72,  92]],\n",
       "\n",
       "       [[ 87,  83,  44],\n",
       "        [ 80,  78,  36],\n",
       "        [ 76,  73,  36],\n",
       "        ...,\n",
       "        [ 75,  80, 100],\n",
       "        [ 71,  78,  97],\n",
       "        [ 65,  71,  93]]], dtype=uint8)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2437"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paths.index((path,label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1443, (224, 224, 3))"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X), X[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(43903, 1443)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(LABELS), len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelBinarizer()\n",
    "X = np.array(X)\n",
    "y = encoder.fit_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# Replace image label with dog tag or zero\n",
    "for image_label in y:\n",
    "    #search for the item\n",
    "    y_position = y.index(image_label)\n",
    "    # Check if dog or not\n",
    "    if image_label in dog_data_part2:\n",
    "        #search for the item\n",
    "        y_position = y.index(image_label)\n",
    "        # Label dog images with ones\n",
    "        y[y_position] = 1\n",
    "    else:\n",
    "        y[y_position] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0}"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "print('The index of', item, 'in the list is:', index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "y;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:dsi]",
   "language": "python",
   "name": "conda-env-dsi-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
