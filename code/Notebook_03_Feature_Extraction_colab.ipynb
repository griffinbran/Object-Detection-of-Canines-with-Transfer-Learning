{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3x9OFMTl-CtI"
   },
   "source": [
    "### Notebook 03: Feature Extraction on Google Colab\n",
    "> * This Notebook requires a high-RAM processor, the bat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jNLeS9LmBZt4",
    "outputId": "aa835552-ce9a-42b1-eca4-155807eff255"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: PyDrive in /usr/local/lib/python3.6/dist-packages (1.3.1)\n",
      "Requirement already satisfied: oauth2client>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from PyDrive) (4.1.3)\n",
      "Requirement already satisfied: google-api-python-client>=1.2 in /usr/local/lib/python3.6/dist-packages (from PyDrive) (1.7.12)\n",
      "Requirement already satisfied: PyYAML>=3.0 in /usr/local/lib/python3.6/dist-packages (from PyDrive) (3.13)\n",
      "Requirement already satisfied: httplib2>=0.9.1 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->PyDrive) (0.17.4)\n",
      "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->PyDrive) (0.4.8)\n",
      "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->PyDrive) (4.6)\n",
      "Requirement already satisfied: six>=1.6.1 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->PyDrive) (1.15.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->PyDrive) (0.2.8)\n",
      "Requirement already satisfied: google-auth>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.2->PyDrive) (1.17.2)\n",
      "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.2->PyDrive) (3.0.1)\n",
      "Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.2->PyDrive) (0.0.4)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.4.1->google-api-python-client>=1.2->PyDrive) (4.1.1)\n",
      "Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.4.1->google-api-python-client>=1.2->PyDrive) (50.3.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install PyDrive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "zxCJu980Bd5_"
   },
   "outputs": [],
   "source": [
    "import os\r\n",
    "from pydrive.auth import GoogleAuth\r\n",
    "from pydrive.drive import GoogleDrive\r\n",
    "from google.colab import auth\r\n",
    "from oauth2client.client import GoogleCredentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "48G1s9Yw-CtK"
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import os\n",
    "# load VGG-16 model: 23 layers, 138,357,544 params, 528MB\n",
    "from keras.applications.vgg16 import VGG16\n",
    "\n",
    "# load and evaluate a saved model \n",
    "import tensorflow as tf\n",
    "from keras import models\n",
    "from keras.models import load_model, Sequential, Model\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, Flatten\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "atN8jnEd-gWC",
    "outputId": "dd7b967b-fe31-4f9f-aef5-9377f92d8a9f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "swGeTmZfCgj5",
    "outputId": "bed791a1-5c81-425b-bc95-bbe92e548e5d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found GPU at: /device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "%tensorflow_version 2.x\r\n",
    "import tensorflow as tf\r\n",
    "device_name = tf.test.gpu_device_name()\r\n",
    "if device_name != '/device:GPU:0':\r\n",
    "  raise SystemError('GPU device not found')\r\n",
    "print('Found GPU at: {}'.format(device_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Yxj_RR1ECgTu",
    "outputId": "499c7906-b20b-4389-eacc-2e467a734bb4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your runtime has 27.4 gigabytes of available RAM\n",
      "\n",
      "You are using a high-RAM runtime!\n"
     ]
    }
   ],
   "source": [
    "from psutil import virtual_memory\r\n",
    "ram_gb = virtual_memory().total / 1e9\r\n",
    "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\r\n",
    "\r\n",
    "if ram_gb < 20:\r\n",
    "  print('To enable a high-RAM runtime, select the Runtime > \"Change runtime type\"')\r\n",
    "  print('menu, and then select High-RAM in the Runtime shape dropdown. Then, ')\r\n",
    "  print('re-execute this cell.')\r\n",
    "else:\r\n",
    "  print('You are using a high-RAM runtime!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "98bLg-nA-CtL",
    "outputId": "a2d31776-09c4-4830-9a9e-6ae3b9762ed3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rA5X6vE0_2S9",
    "outputId": "4e8d8545-89b5-469c-c308-3e1b20693fc1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.6.9\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xppkT_WJqMGa",
    "outputId": "a2e39900-4c5a-4708-b247-b78e3dabc7ee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.5.0\n"
     ]
    }
   ],
   "source": [
    "!ipython --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UpYBEvWQ-CtM",
    "outputId": "cbb53262-79cb-4164-80b2-d9ef364f9997"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default GPU Device:/device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "# Sometimes my tensorflow tries to use GPU support but I don't want it to, have had many errors.\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "# #tf.compat.v1.Session(), .compat.v1.\n",
    "# sess_cpu = tf.compat.v1.Session(config=tf.compat.v1.ConfigProto(device_count={'GPU': 0}))\n",
    "# print(tf.__version__)\n",
    "# if tf.test.gpu_device_name():\n",
    "#     print('Default GPU Device:{}'.format(tf.test.gpu_device_name()))\n",
    "# else:\n",
    "#     print(\"Please install GPU version of TF\")\n",
    "\n",
    "if tf.test.gpu_device_name():\n",
    "    print('Default GPU Device:{}'.format(tf.test.gpu_device_name()))\n",
    "else:\n",
    "    print(\"Please install GPU version of TF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oSe67vWz_aMK",
    "outputId": "e53089b5-d25c-4cb5-e440-03ba1d4a7d0b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading binary X_train from pkl...\n",
      "Attempting to load binary y_valid from pkl...\n",
      "Training data loaded!\n",
      "\n",
      "CPU times: user 5.33 s, sys: 21.1 s, total: 26.5 s\n",
      "Wall time: 2min 27s\n"
     ]
    }
   ],
   "source": [
    "%%time\r\n",
    "# Load training Data\r\n",
    "print('Loading binary X_train from pkl...')\r\n",
    "# Save X_train and y_train lists as .pkl files from Mounted G-Drive\r\n",
    "with open('/content/drive/MyDrive/X_training_image_data.pkl', 'rb') as file:\r\n",
    "    X_train = np.array(pickle.load(file))\r\n",
    "\r\n",
    "print('Attempting to load binary y_valid from pkl...')\r\n",
    "with open('/content/drive/MyDrive/y_training_labels.pkl', 'rb') as file:\r\n",
    "    y_train = np.array(pickle.load(file))\r\n",
    "    \r\n",
    "print('Training data loaded!')\r\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9Q8RIAKk-CtM",
    "outputId": "f27712bb-7b38-493c-a1ad-8ab61f679fc0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting to load binary X_valid from pkl...\n",
      "Attempting to load binary y_valid from pkl...\n",
      "Validation data loaded!\n",
      "\n",
      "CPU times: user 4.63 s, sys: 13.4 s, total: 18.1 s\n",
      "Wall time: 1min 40s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Load Validation Data\n",
    "print('Attempting to load binary X_valid from pkl...')\n",
    "\n",
    "# Load X_valid and y_valid lists as .pkl files from Mounted G-Drive\n",
    "with open('/content/drive/MyDrive/X_validation_image_data.pkl', 'rb') as file:\n",
    "    X_valid = np.array(pickle.load(file))\n",
    "print('Attempting to load binary y_valid from pkl...')\n",
    "with open('/content/drive/MyDrive/y_validation_labels.pkl', 'rb') as file:\n",
    "    y_valid = np.array(pickle.load(file))\n",
    "\n",
    "print('Validation data loaded!')\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aWNm84CpYbPm",
    "outputId": "d492b391-9d45-4563-9007-151e59f5462e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64346, 64346, numpy.ndarray, (224, 224, 3), numpy.ndarray)"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train), len(y_train), type(X_train), X_valid[0].shape, type(X_valid[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "000lr4h4-CtN",
    "outputId": "f835bc99-660e-42c3-ec0e-bbe87c79ffe4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(43733, 43733, numpy.ndarray, (224, 224, 3), numpy.ndarray)"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_valid), len(y_valid), type(X_valid), X_train[0].shape, type(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2TlPnjmE-CtN",
    "outputId": "0bc5a1c6-ab80-4825-cd8a-f5266b28d92b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({0, 1}, {0, 1})"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(y_valid), set(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "M1giAs8d-CtP",
    "outputId": "4772eb49-4520-453e-f410-b7cb750a909f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(224, 224, 3)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(X_valid[0].shape)\n",
    "print(type(X_valid[0]))\n",
    "print(type(X_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TF8j6_pF-CtP",
    "outputId": "6beb5891-6fc7-4571-92ba-94087e968464"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(224, 224, 3)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(X_train[0].shape)\n",
    "print(type(X_train[0]))\n",
    "print(type(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jyMH1P6Y-CtQ",
    "outputId": "028d1d33-f648-46e5-d06e-6b1a1a5187db"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 0\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# https://keras.io/api/applications/vgg/#vgg16-function\n",
    "# https://towardsdatascience.com/a-demonstration-of-transfer-learning-of-vgg-convolutional-neural-network-pre-trained-model-with-c9f5b8b1ab0a\n",
    "\n",
    "# Adjust input size of the model for include_top=False\n",
    "new_input = Input(shape=(224,224,3)) \n",
    "\n",
    "# load the model weights into memory\n",
    "# Cut-Off the VGG-16 Model after the last Conv2D layer (18)\n",
    "base_model = VGG16(\n",
    "                include_top=False,   # include_top=False to load model wihtout the fully-connected output layers used to make predictions\n",
    "                weights=\"imagenet\", # Weights are downloaded automatically when instantiating a model: Keras Applications ~/.keras/models/\n",
    "                input_tensor=new_input, # --> MUST INCLUDE THIS PARAM TO FEED CLASSIFIER VGG-16 WEIGHTS\n",
    "                input_shape=None,\n",
    "                pooling=None,\n",
    "                classes=1000,\n",
    "                classifier_activation=\"softmax\",\n",
    "            )\n",
    "\n",
    "# Freeze base layers from training\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Summarize the loaded model after dropping the dense top layers for binary classification\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4BYkyeAM-CtQ",
    "outputId": "ac61f61c-c37a-4d63-e4d4-cbbe58d8ed62"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "vgg16 (Functional)           (None, 7, 7, 512)         14714688  \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 8192)              205529088 \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2048)              16779264  \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2048)              4196352   \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 2049      \n",
      "=================================================================\n",
      "Total params: 241,221,441\n",
      "Trainable params: 226,506,753\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Add dense layers to base_model loaded\n",
    "batch_transfer_model = Sequential()\n",
    "batch_transfer_model.add(base_model)\n",
    "# Flatten layer to transform 4D --> 2D for \"fully-connected\" dense layers\n",
    "batch_transfer_model.add(Flatten())\n",
    "# Hiddden dense layer with 8,192 nodes\n",
    "batch_transfer_model.add(Dense(8192, activation='relu'))\n",
    "batch_transfer_model.add(Dropout(0.3))\n",
    "# Hidden dense layer with 2,048 nodes\n",
    "batch_transfer_model.add(Dense(2048, activation='relu'))\n",
    "batch_transfer_model.add(Dropout(0.1))\n",
    "# Hidden dense layer with 2,048 nodes\n",
    "batch_transfer_model.add(Dense(2048, activation='relu'))\n",
    "batch_transfer_model.add(Dense(1, activation='sigmoid'))\n",
    "# Summarize the new binary classifier to check if all looks ok\n",
    "batch_transfer_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mJAFcoys-CtQ",
    "outputId": "86d7e9d4-fcf9-419c-8c11-5bc1835ea152"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 4, 8, 16, 32, 64, 128, 256, 512]"
      ]
     },
     "execution_count": 25,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[2**i for i in range(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "LDbuJiH2-CtR"
   },
   "outputs": [],
   "source": [
    "# Establish number of epochs and batch size\n",
    "b_size = 64 # choose base-2\n",
    "nb_epochs = 10\n",
    "\n",
    "# Initialize training image generator for data augmentation\n",
    "# Data Augmentation as a form of regularization: random translate/rotate/resize images on the fly\n",
    "# Augmentor from https://www.sunjackson.com/post/700/ with values & name changed\n",
    "augmentor = ImageDataGenerator(rotation_range = 32,\n",
    "                               zoom_range = 0.16,\n",
    "                               width_shift_range = 0.2,\n",
    "                               height_shift_range = 0.2,\n",
    "                               shear_range = 0.16,\n",
    "                               horizontal_flip = True,\n",
    "                               fill_mode = \"nearest\")\n",
    "\n",
    "# Compile the model before training\n",
    "batch_transfer_model.compile(\n",
    "              # Optimization Algorithm, Extension of Stochastic Gradient Descent, \n",
    "              optimizer = 'adam', # lr varies from 1 to 0(perfect)\n",
    "              # Objective Function, determines what will be used to fit the model\n",
    "              loss = 'binary_crossentropy',\n",
    "              # Accuracy metric helps with interpretation of model performance\n",
    "              metrics = ['accuracy'])\n",
    "              #options = run_opts)\n",
    "\n",
    "# Save the weights at each epoch they improve the model's performance\n",
    "checkpoint_saver = ModelCheckpoint(filepath = '/content/drive/MyDrive/batch_transfer_dog.h5', # transfer_dog.h5 ---> 10epochs/256batch/no augmentor\n",
    "                                    verbose = 1,                                              # batch_transfer_dog.h5 --> 10/128 with augmentor\n",
    "                                    save_best_only = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0u0EHARg-CtR"
   },
   "source": [
    "#### Notes from General Assembly-DSI Lessons "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RyEatecf-CtR",
    "outputId": "8670d758-87c1-47dd-f6b3-3a9a66be5eb1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "252/252 [==============================] - ETA: 0s - loss: 0.1339 - accuracy: 0.9697\n",
      "Epoch 00001: val_loss improved from inf to 0.10588, saving model to /content/drive/MyDrive/transfer_dog.h5\n",
      "252/252 [==============================] - 225s 892ms/step - loss: 0.1339 - accuracy: 0.9697 - val_loss: 0.1059 - val_accuracy: 0.9736\n",
      "Epoch 2/10\n",
      "252/252 [==============================] - ETA: 0s - loss: 0.0848 - accuracy: 0.9764\n",
      "Epoch 00002: val_loss improved from 0.10588 to 0.09952, saving model to /content/drive/MyDrive/transfer_dog.h5\n",
      "252/252 [==============================] - 224s 890ms/step - loss: 0.0848 - accuracy: 0.9764 - val_loss: 0.0995 - val_accuracy: 0.9752\n",
      "Epoch 3/10\n",
      "252/252 [==============================] - ETA: 0s - loss: 0.0397 - accuracy: 0.9888\n",
      "Epoch 00003: val_loss did not improve from 0.09952\n",
      "252/252 [==============================] - 200s 793ms/step - loss: 0.0397 - accuracy: 0.9888 - val_loss: 0.1269 - val_accuracy: 0.9708\n",
      "Epoch 4/10\n",
      "252/252 [==============================] - ETA: 0s - loss: 0.0235 - accuracy: 0.9932\n",
      "Epoch 00004: val_loss did not improve from 0.09952\n",
      "252/252 [==============================] - 200s 792ms/step - loss: 0.0235 - accuracy: 0.9932 - val_loss: 0.1387 - val_accuracy: 0.9664\n",
      "Epoch 5/10\n",
      "252/252 [==============================] - ETA: 0s - loss: 0.0162 - accuracy: 0.9962\n",
      "Epoch 00005: val_loss did not improve from 0.09952\n",
      "252/252 [==============================] - 200s 792ms/step - loss: 0.0162 - accuracy: 0.9962 - val_loss: 0.2562 - val_accuracy: 0.9740\n",
      "Epoch 6/10\n",
      "252/252 [==============================] - ETA: 0s - loss: 0.0284 - accuracy: 0.9959\n",
      "Epoch 00006: val_loss did not improve from 0.09952\n",
      "252/252 [==============================] - 200s 792ms/step - loss: 0.0284 - accuracy: 0.9959 - val_loss: 0.1711 - val_accuracy: 0.9756\n",
      "Epoch 7/10\n",
      "252/252 [==============================] - ETA: 0s - loss: 0.0179 - accuracy: 0.9969\n",
      "Epoch 00007: val_loss did not improve from 0.09952\n",
      "252/252 [==============================] - 200s 792ms/step - loss: 0.0179 - accuracy: 0.9969 - val_loss: 0.1368 - val_accuracy: 0.9754\n",
      "Epoch 8/10\n",
      "252/252 [==============================] - ETA: 0s - loss: 0.0083 - accuracy: 0.9980\n",
      "Epoch 00008: val_loss did not improve from 0.09952\n",
      "252/252 [==============================] - 200s 792ms/step - loss: 0.0083 - accuracy: 0.9980 - val_loss: 0.1712 - val_accuracy: 0.9720\n",
      "Epoch 9/10\n",
      "252/252 [==============================] - ETA: 0s - loss: 0.0076 - accuracy: 0.9984\n",
      "Epoch 00009: val_loss did not improve from 0.09952\n",
      "252/252 [==============================] - 200s 792ms/step - loss: 0.0076 - accuracy: 0.9984 - val_loss: 0.3548 - val_accuracy: 0.9750\n",
      "Epoch 10/10\n",
      "252/252 [==============================] - ETA: 0s - loss: 0.0111 - accuracy: 0.9979\n",
      "Epoch 00010: val_loss did not improve from 0.09952\n",
      "252/252 [==============================] - 200s 792ms/step - loss: 0.0111 - accuracy: 0.9979 - val_loss: 0.2085 - val_accuracy: 0.9748\n"
     ]
    }
   ],
   "source": [
    "# Fit the transfer model using stochastic gradient descent\n",
    "transfer_history = transfer_model.fit(x=X_train, \n",
    "                                   y=y_train,\n",
    "                                   validation_data=(X_valid, y_valid),\n",
    "                                   batch_size=b_size,\n",
    "                                   epochs=nb_epochs,\n",
    "                                   callbacks = [checkpoint_saver],\n",
    "                                   verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uALGzXBrl26j"
   },
   "outputs": [],
   "source": [
    "# Keras calls data generator function: augmentor.flow --> yields batch to .fit_generator\r\n",
    "batch_transfer_history = batch_transfer_model.fit_generator(augmentor.flow(X_train, y_train, batch_size = b_size),\r\n",
    "                        validation_data = (X_valid, y_valid),\r\n",
    "                        steps_per_epoch = len(X_train) // b_size, \r\n",
    "                        epochs=nb_epochs,\r\n",
    "                        callbacks=[checkpoint_saver], # callback objects can write logs to monitor metrics, save model to disk, early stopping, or view internal states/stats after each batch or epoch\r\n",
    "                        verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yE8EOgfZ-CtS"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "# load weights into new model\n",
    "loaded_model = '../../assets/model_vgg16_flatten.h5'\n",
    "\n",
    "# Load base model weights\n",
    "loaded_model = load_model(loaded_model)\n",
    "\n",
    "#loaded_model.load_weights(\"~\\.keras\\models.h5\") \n",
    "print(\"Loaded model from disk\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fztIQQec-CtS"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "# Cut-Off the VGG-16 Model after the last Conv2D layer (18)\n",
    "dogg16 = models.Model(inputs=base_model.input,\n",
    "                           outputs=base_model.get_layer('flatten').output\n",
    "                          )\n",
    "'''\n",
    "# Extract features\n",
    "#flatten_features = model_vgg16.predict(x)\n",
    "# save model and architecture to single file\n",
    "#dogg16.save('../../model_dogg16.h5') \n",
    "#print(\"Saved model to disk\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "Notebook-03-Feature-Extraction.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
